{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from rtbm.riemann_theta.riemann_theta import RiemannTheta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import theano\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, Reshape  \n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import time\n",
    "\n",
    "from rtbm import RTBM, minimizer\n",
    "\n",
    "import rtbm.layers as layers\n",
    "import rtbm.model as mdl\n",
    "\n",
    "from rtbm.costfunctions import mse\n",
    "from rtbm.activations import sigmoid, linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "MNIST_train = pd.read_csv('~/data/mnist_train.csv', delimiter=\",\",header=None).values\n",
    "MNIST_test  = pd.read_csv('~/data/mnist_test.csv', delimiter=\",\",header=None).values\n",
    "\n",
    "# Prepare data (normalized onto [0,1])\n",
    "Y_train = MNIST_train[0:10000,0]\n",
    "X_train = MNIST_train[0:10000,1:]/255.0\n",
    "\n",
    "Y_test = MNIST_test[:,0]\n",
    "X_test = MNIST_test[:,1:]/255.0\n",
    "\n",
    "enc = LabelBinarizer()\n",
    "enc.fit(np.diag([1,1,1,1,1,1,1,1,1,1]))\n",
    "enc.classes_ = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "T=enc.transform(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras (500 linear + 100 linear + 1 linear + MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() \n",
    "\n",
    "model.add(Dense(500,  input_dim=784))\n",
    "model.add(Activation('linear'))\n",
    "#model.add(Dense(100,  input_dim=784))\n",
    "#model.add(Activation('linear'))\n",
    "model.add(Dense(output_dim=1))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "\n",
    "sgd = SGD(lr=0.001)\n",
    "\n",
    "tic = time.clock()\n",
    "\n",
    "model.compile(loss='mse', optimizer=sgd)\n",
    "\n",
    "toc = time.clock()\n",
    "\n",
    "print(\"Compile time: \",toc-tic)\n",
    "\n",
    "tic = time.clock()\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=100, nb_epoch=100, validation_data=None, shuffle=False, verbose=1)  \n",
    "toc = time.clock()\n",
    "\n",
    "print(\"Run time: \",toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On train set\n",
    "P=np.abs(np.round(np.real(model.predict(X_train)))).flatten()\n",
    "\n",
    "\n",
    "print(classification_report(Y_train,P.T))\n",
    "print(confusion_matrix(Y_train, P.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On test set\n",
    "P=np.abs(np.round(np.real(model.predict(X_test)))).flatten()\n",
    "\n",
    "\n",
    "print(classification_report(Y_test,P.T))\n",
    "print(confusion_matrix(Y_test, P.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Theta and SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |████████████████████| 100.0% | iteration 100 in 48.26(s) | cost = 4.846159\n"
     ]
    }
   ],
   "source": [
    "M = mdl.Model()\n",
    "M.add(layers.NonLinear(784,500,linear()))\n",
    "#M.add(layers.NonLinear(500,100,linear()))\n",
    "M.add(layers.NonLinear(500,1,linear()))\n",
    "M.set_bound(3)\n",
    "\n",
    "minim = minimizer.SGD()\n",
    "sol=minim.train(mse(), M, np.transpose(X_train), Y_train.reshape(1,len(Y_train)), lr=0.001, maxiter=100, batch_size=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.89      0.15      0.26      1001\n",
      "        1.0       0.14      0.07      0.09      1127\n",
      "        2.0       0.16      0.21      0.19       991\n",
      "        3.0       0.19      0.32      0.24      1032\n",
      "        4.0       0.08      0.16      0.11       980\n",
      "        5.0       0.08      0.15      0.10       863\n",
      "        6.0       0.11      0.14      0.12      1014\n",
      "        7.0       0.27      0.21      0.24      1070\n",
      "        8.0       0.14      0.06      0.08       944\n",
      "        9.0       0.49      0.08      0.13       978\n",
      "       10.0       0.00      0.00      0.00         0\n",
      "       11.0       0.00      0.00      0.00         0\n",
      "       12.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.26      0.16      0.16     10000\n",
      "\n",
      "[[149 319 254 134  80  38  19   7   1   0   0   0   0]\n",
      " [  0  78 474 367 148  40  15   4   1   0   0   0   0]\n",
      " [ 14  78 213 292 235 114  37   6   1   1   0   0   0]\n",
      " [  4  27 162 329 259 148  72  13  16   1   1   0   0]\n",
      " [  0   5  13  55 160 274 255 128  72  16   2   0   0]\n",
      " [  0  17 112 244 264 126  72  23   4   1   0   0   0]\n",
      " [  0   7  45 177 322 244 145  59  13   2   0   0   0]\n",
      " [  0   3  10  51 146 245 262 228  86  34   5   0   0]\n",
      " [  0   1  15  95 205 216 191 135  55  23   6   1   1]\n",
      " [  0   4   3  19  70 125 259 250 146  76  25   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# On train set\n",
    "P=np.abs(np.round(np.real(M.predict(np.transpose(X_train)))))\n",
    "\n",
    "print(classification_report(Y_train,P.T))\n",
    "print(confusion_matrix(Y_train, P.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.89      0.15      0.26      1001\n",
      "        1.0       0.14      0.07      0.09      1127\n",
      "        2.0       0.16      0.21      0.19       991\n",
      "        3.0       0.19      0.32      0.24      1032\n",
      "        4.0       0.08      0.16      0.11       980\n",
      "        5.0       0.08      0.15      0.10       863\n",
      "        6.0       0.11      0.14      0.12      1014\n",
      "        7.0       0.27      0.21      0.24      1070\n",
      "        8.0       0.14      0.06      0.08       944\n",
      "        9.0       0.49      0.08      0.13       978\n",
      "       10.0       0.00      0.00      0.00         0\n",
      "       11.0       0.00      0.00      0.00         0\n",
      "       12.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.26      0.16      0.16     10000\n",
      "\n",
      "[[149 319 254 134  80  38  19   7   1   0   0   0   0]\n",
      " [  0  78 474 367 148  40  15   4   1   0   0   0   0]\n",
      " [ 14  78 213 292 235 114  37   6   1   1   0   0   0]\n",
      " [  4  27 162 329 259 148  72  13  16   1   1   0   0]\n",
      " [  0   5  13  55 160 274 255 128  72  16   2   0   0]\n",
      " [  0  17 112 244 264 126  72  23   4   1   0   0   0]\n",
      " [  0   7  45 177 322 244 145  59  13   2   0   0   0]\n",
      " [  0   3  10  51 146 245 262 228  86  34   5   0   0]\n",
      " [  0   1  15  95 205 216 191 135  55  23   6   1   1]\n",
      " [  0   4   3  19  70 125 259 250 146  76  25   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# On train set\n",
    "P=np.abs(np.round(np.real(M.predict(np.transpose(X_train)))))\n",
    "\n",
    "print(classification_report(Y_train,P.T))\n",
    "print(confusion_matrix(Y_train, P.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras (200 sigmoids + 10 sigmoids + 1 linear + MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() \n",
    "\n",
    "model.add(Dense(10,  input_dim=784))\n",
    "model.add(Activation('sigmoid'))\n",
    "#model.add(Dense(10))\n",
    "#model.add(Activation('sigmoid'))\n",
    "model.add(Dense(output_dim=1))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "\n",
    "sgd = SGD(lr=0.1)\n",
    "\n",
    "tic = time.clock()\n",
    "\n",
    "model.compile(loss='mse', optimizer=sgd)\n",
    "\n",
    "toc = time.clock()\n",
    "\n",
    "print(\"Compile time: \",toc-tic)\n",
    "\n",
    "tic = time.clock()\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=10000, nb_epoch=200, validation_data=None, shuffle=False, verbose=0)  \n",
    "toc = time.clock()\n",
    "\n",
    "print(\"Run time: \",toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On train set\n",
    "P=np.abs(np.round(np.real(model.predict(X_train)))).flatten()\n",
    "\n",
    "\n",
    "print(classification_report(Y_train,P.T))\n",
    "print(confusion_matrix(Y_train, P.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On test set\n",
    "P=np.abs(np.round(np.real(model.predict(X_test)))).flatten()\n",
    "\n",
    "\n",
    "print(classification_report(Y_test,P.T))\n",
    "print(confusion_matrix(Y_test, P.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Theta and SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = mdl.Model()\n",
    "M.add(layers.NonLinear(784,10,sigmoid()))\n",
    "#M.add(layers.NonLinear(200,10,sigmoid()))\n",
    "M.add(layers.Linear(10,1))\n",
    "\n",
    "minim = minimizer.SGD()\n",
    "sol=minim.train(mse(), M, np.transpose(X_train), Y_train.reshape(1,len(Y_train)), lr=0.1, maxiter=200, batch_size=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On train set\n",
    "P=np.abs(np.round(np.real(M.predict(np.transpose(X_train)))))\n",
    "\n",
    "print(classification_report(Y_train,P.T))\n",
    "print(confusion_matrix(Y_train, P.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On test set\n",
    "P=np.abs(np.round(np.real(M.predict(np.transpose(X_test)))))\n",
    "\n",
    "print(classification_report(Y_test,P.T))\n",
    "print(confusion_matrix(Y_test, P.T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras (200 sigmoids + 10 Softmax + MSE)¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() \n",
    "\n",
    "model.add(Dense(200,  input_dim=784))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10,  input_dim=784))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "sgd = SGD(lr=0.001)\n",
    "\n",
    "tic = time.clock()\n",
    "\n",
    "model.compile(loss='mse', optimizer=sgd)\n",
    "\n",
    "toc = time.clock()\n",
    "\n",
    "print(\"Compile time: \",toc-tic)\n",
    "\n",
    "tic = time.clock()\n",
    "\n",
    "model.fit(X_train, T, batch_size=1000, nb_epoch=100, validation_data=None, shuffle=False, verbose=0)  \n",
    "toc = time.clock()\n",
    "\n",
    "print(\"Run time: \",toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On train set\n",
    "P=np.argmax(model.predict(X_train),axis=1)\n",
    "\n",
    "print(classification_report(Y_train,P.T))\n",
    "print(confusion_matrix(Y_train, P.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On test set\n",
    "P=np.argmax(model.predict(X_test),axis=1)\n",
    "\n",
    "print(classification_report(Y_test,P.T))\n",
    "print(confusion_matrix(Y_test, P.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = mdl.Model()\n",
    "M.add(layers.NonLinear(784,200,sigmoid()))\n",
    "M.add(layers.Linear(200,10))\n",
    "M.add(layers.SoftMaxLayer(10))\n",
    "\n",
    "minim = minimizer.SGD()\n",
    "sol=minim.train(mse(), M, np.transpose(X_train), T.T, lr=0.001, maxiter=200, batch_size=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P=np.argmax(M.predict(np.transpose(X_train)),axis=0)\n",
    "\n",
    "print(classification_report(Y_train,P.T))\n",
    "print(confusion_matrix(Y_train, P.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P=np.argmax(M.predict(np.transpose(X_test)),axis=0)\n",
    "\n",
    "\n",
    "print(classification_report(Y_test,P.T))\n",
    "print(confusion_matrix(Y_test, P.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
